{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import gc\n",
    "import load as ld\n",
    "import preprocessing as pp\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn import model_selection, preprocessing, metrics\n",
    "import lightgbm as lgb\n",
    "import training as tr\n",
    "import matplotlib.pyplot as plt\n",
    "import pandas as pd\n",
    "\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "DATADIR = \"input/\"\n",
    "SUBMISSIONS_DIR = \"submissions/\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#import zipfile\n",
    "#zip_ref = zipfile.ZipFile(DATADIR + \"historical_transactions.csv.zip\", 'r')\n",
    "#zip_ref.extractall(DATADIR)\n",
    "#zip_ref.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def get_tree_models():\n",
    "    lgb_params = {}\n",
    "    #lgb_params['nthread'] = 3\n",
    "    lgb_params['n_estimators'] = 10000\n",
    "    lgb_params['learning_rate'] = 0.005\n",
    "    lgb_params['colsample_bytree'] = 0.75\n",
    "    lgb_params['subsample'] = 0.8\n",
    "    #lgb_params['max_depth'] = 10\n",
    "    #lgb_params[\"reg_alpha\"] = 0.041545473\n",
    "    #lgb_params['reg_lambda'] = 0.0735294\n",
    "    #lgb_params['num_leaves'] = 34\n",
    "    lgb_params['metric'] = 'rmse'\n",
    "    lgb_params['objective'] = 'regression'\n",
    "\n",
    "    \n",
    "    lgb_fit_params = {}\n",
    "    lgb_fit_params['verbose_eval'] = 100\n",
    "    lgb_fit_params['early_stopping_rounds'] = 200\n",
    "    lgb_fit_params['valid_sets'] = {}\n",
    "    lgb_fit_params['valid_names'] = [\"validation\"]\n",
    "    \n",
    "    xgb_params = dict()\n",
    "    xgb_params[\"booster\"] = \"gbtree\"\n",
    "    xgb_params[\"objective\"] = \"reg:linear\"\n",
    "    #xgb_params[\"colsample_bytree\"] = 0.9497036\n",
    "    #xgb_params[\"subsample\"] = 0.8715623\n",
    "    #xgb_params[\"max_depth\"] = 8\n",
    "    #xgb_params['reg_alpha'] = 0.041545473\n",
    "    #xgb_params['reg_lambda'] = 0.0735294\n",
    "    xgb_params[\"learning_rate\"] = 0.005\n",
    "    #xgb_params[\"min_child_weight\"] = 39.3259775\n",
    "    xgb_params['eval_metric'] = 'rmse'\n",
    "    xgb_params['silent'] = 1\n",
    "    \n",
    "    xgb_fit_params = {}\n",
    "    xgb_fit_params['verbose_eval'] = 100\n",
    "    xgb_fit_params['early_stopping_rounds'] = 200\n",
    "    xgb_fit_params['evals'] = {}\n",
    "    xgb_fit_params['num_boost_round'] = 10000\n",
    "\n",
    "    tree_models = []   \n",
    "\n",
    "    lgbm = tr.LightGBMRegressorWrapper(params = lgb_params, name = \"lgbm\")\n",
    "    xgb = tr.XgbRegressorWrapper(params = xgb_params, name = \"xgb\")\n",
    "    \n",
    "    tree_models.append((lgbm, lgb_fit_params))\n",
    "    #tree_models.append((xgb, xgb_fit_params))\n",
    "        \n",
    "    return tree_models"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def run_lgb(train_X, train_y, val_X, val_y, test_X, features = None, verbose = 50, early_stopping_rounds = 200):\n",
    "    \n",
    "    lgb_params = {\n",
    "            \"objective\" : \"regression\",\n",
    "            \"metric\" : \"rmse\",\n",
    "            \"num_leaves\" : 30,\n",
    "            \"min_child_weight\" : 50,\n",
    "            \"learning_rate\" : 0.01,\n",
    "            \"bagging_fraction\" : 0.8,\n",
    "            \"feature_fraction\" : 0.8,\n",
    "            \"bagging_frequency\" : 5,\n",
    "            \"bagging_seed\" : 2018,\n",
    "            \"num_iterations\" : 2000\n",
    "        }\n",
    "       \n",
    "    if features == None:\n",
    "        features = train_X.columns.tolist()\n",
    "        \n",
    "    #train_X, val_X, train_y, val_y = train_test_split(X, y, random_state = 2018)\n",
    "    \n",
    "    lgb_train = lgb.Dataset(data = train_X, label = train_y, feature_name = features)\n",
    "    lgb_val = lgb.Dataset(data = val_X, label = val_y, feature_name = features)\n",
    "    \n",
    "    lgb_booster = lgb.train(params = lgb_params, train_set = lgb_train, valid_sets = [lgb_val], valid_names = [\"validation\"], \n",
    "            verbose_eval = verbose, early_stopping_rounds = early_stopping_rounds)\n",
    "    \n",
    "    predictions = lgb_booster.predict(test_X, num_iteration = lgb_booster.best_iteration)\n",
    "    \n",
    "    return lgb_booster, predictions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def get_datasets(debug_size, silent, treat_duplicated = True):\n",
    "    train, test = ld.get_processed_files(debug_size, silent)\n",
    "    features = [f for f in train.columns if f not in ['target', 'card_id', 'index', 'first_active_month']]\n",
    "    \n",
    "    train_y = train['target']\n",
    "    train_X = train.loc[:, features]\n",
    "\n",
    "    ids = test['card_id']\n",
    "    test_X = test.loc[:, features]\n",
    "    \n",
    "    return train_X, train_y, test_X, ids"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "debug_size = 0\n",
    "silent = False\n",
    "verbose = 10\n",
    "early_stopping_rounds = 100"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Process train and test - Start!\n",
      "Train shape: (201917, 16)\n",
      "Test shape: (123623, 15)\n",
      "Process train and test - Done in 2s\n",
      "\n",
      "Process Historic Transactions - Start!\n",
      "Memory usage of dataframe is 3109.54 MB\n",
      "Memory usage after optimization is: 1749.11 MB\n",
      "Decreased by 43.7%\n",
      "\n",
      "Calculating Interval since first - Start!\n",
      "Calculating Interval since first - Done in 25s\n",
      "\n",
      "Concatenating - Start!\n",
      "Concatenating - Done in 15s\n",
      "\n",
      "Calculating Interval since last - Start!\n",
      "Calculating Interval since last - Done in 15s\n",
      "\n",
      "Calculating Counts - Start!\n",
      "Calculating Counts - Done in 5s\n",
      "\n",
      "Calculating NUNIQUE - Start!\n",
      "Calculating NUNIQUE - Done in 104s\n",
      "\n",
      "Calculating Engineered Features - Numerical - Start!\n",
      "Calculating Engineered Features - Numerical - Done in 187s\n",
      "\n",
      "Calculating Engineered Features - Categorical - Start!\n",
      "Calculating Engineered Features - Categorical - Done in 25s\n",
      "\n",
      "Historic Transactions shape: (325540, 63)\n",
      "Process Historic Transactions - Done in 508s\n",
      "\n"
     ]
    }
   ],
   "source": [
    "train_X, train_y, test_X, ids = get_datasets(debug_size = debug_size, silent = silent)\n",
    "features = train_X.columns.tolist()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Full Model Run - Start!\n",
      "Regrerssors will be fitted with 75 out of 75 features\n",
      "Run lgbm - Start!\n",
      "Training until validation scores don't improve for 200 rounds.\n",
      "[100]\tvalidation's rmse: 3.76867\n",
      "[200]\tvalidation's rmse: 3.74885\n",
      "[300]\tvalidation's rmse: 3.74075\n",
      "[400]\tvalidation's rmse: 3.73694\n",
      "[500]\tvalidation's rmse: 3.73434\n",
      "[600]\tvalidation's rmse: 3.733\n",
      "[700]\tvalidation's rmse: 3.73246\n",
      "[800]\tvalidation's rmse: 3.73148\n",
      "[900]\tvalidation's rmse: 3.73135\n",
      "[1000]\tvalidation's rmse: 3.73113\n",
      "[1100]\tvalidation's rmse: 3.73091\n",
      "[1200]\tvalidation's rmse: 3.73059\n",
      "[1300]\tvalidation's rmse: 3.73047\n",
      "[1400]\tvalidation's rmse: 3.73049\n",
      "[1500]\tvalidation's rmse: 3.73041\n",
      "[1600]\tvalidation's rmse: 3.73046\n",
      "Early stopping, best iteration is:\n",
      "[1472]\tvalidation's rmse: 3.73032\n",
      "Fold  1 RMSE : 3.730322\n",
      "Training until validation scores don't improve for 200 rounds.\n",
      "[100]\tvalidation's rmse: 3.80235\n",
      "[200]\tvalidation's rmse: 3.78221\n",
      "[300]\tvalidation's rmse: 3.77105\n",
      "[400]\tvalidation's rmse: 3.76439\n",
      "[500]\tvalidation's rmse: 3.76061\n",
      "[600]\tvalidation's rmse: 3.75839\n",
      "[700]\tvalidation's rmse: 3.75629\n",
      "[800]\tvalidation's rmse: 3.75512\n",
      "[900]\tvalidation's rmse: 3.75392\n",
      "[1000]\tvalidation's rmse: 3.7533\n",
      "[1100]\tvalidation's rmse: 3.75304\n",
      "[1200]\tvalidation's rmse: 3.75292\n",
      "[1300]\tvalidation's rmse: 3.75285\n",
      "[1400]\tvalidation's rmse: 3.75271\n",
      "[1500]\tvalidation's rmse: 3.75264\n",
      "[1600]\tvalidation's rmse: 3.7527\n",
      "Early stopping, best iteration is:\n",
      "[1478]\tvalidation's rmse: 3.75261\n",
      "Fold  2 RMSE : 3.752612\n",
      "Training until validation scores don't improve for 200 rounds.\n",
      "[100]\tvalidation's rmse: 3.88442\n",
      "[200]\tvalidation's rmse: 3.86562\n",
      "[300]\tvalidation's rmse: 3.85571\n",
      "[400]\tvalidation's rmse: 3.85108\n",
      "[500]\tvalidation's rmse: 3.84805\n",
      "[600]\tvalidation's rmse: 3.84636\n",
      "[700]\tvalidation's rmse: 3.84527\n",
      "[800]\tvalidation's rmse: 3.84419\n",
      "[900]\tvalidation's rmse: 3.84334\n",
      "[1000]\tvalidation's rmse: 3.84261\n",
      "[1100]\tvalidation's rmse: 3.84213\n",
      "[1200]\tvalidation's rmse: 3.84204\n",
      "[1300]\tvalidation's rmse: 3.84214\n",
      "[1400]\tvalidation's rmse: 3.84223\n",
      "Early stopping, best iteration is:\n",
      "[1212]\tvalidation's rmse: 3.84202\n",
      "Fold  3 RMSE : 3.842018\n",
      "Training until validation scores don't improve for 200 rounds.\n",
      "[100]\tvalidation's rmse: 3.85993\n",
      "[200]\tvalidation's rmse: 3.84015\n",
      "[300]\tvalidation's rmse: 3.82966\n",
      "[400]\tvalidation's rmse: 3.82416\n",
      "[500]\tvalidation's rmse: 3.81993\n",
      "[600]\tvalidation's rmse: 3.81743\n",
      "[700]\tvalidation's rmse: 3.81579\n",
      "[800]\tvalidation's rmse: 3.81442\n",
      "[900]\tvalidation's rmse: 3.81331\n",
      "[1000]\tvalidation's rmse: 3.81235\n",
      "[1100]\tvalidation's rmse: 3.81141\n",
      "[1200]\tvalidation's rmse: 3.81075\n",
      "[1300]\tvalidation's rmse: 3.81032\n",
      "[1400]\tvalidation's rmse: 3.80998\n",
      "[1500]\tvalidation's rmse: 3.80991\n",
      "[1600]\tvalidation's rmse: 3.80976\n",
      "[1700]\tvalidation's rmse: 3.80993\n",
      "Early stopping, best iteration is:\n",
      "[1599]\tvalidation's rmse: 3.80976\n",
      "Fold  4 RMSE : 3.809756\n",
      "Training until validation scores don't improve for 200 rounds.\n",
      "[100]\tvalidation's rmse: 3.72467\n",
      "[200]\tvalidation's rmse: 3.70453\n",
      "[300]\tvalidation's rmse: 3.69522\n",
      "[400]\tvalidation's rmse: 3.68907\n",
      "[500]\tvalidation's rmse: 3.68598\n",
      "[600]\tvalidation's rmse: 3.68437\n",
      "[700]\tvalidation's rmse: 3.68286\n",
      "[800]\tvalidation's rmse: 3.68237\n",
      "[900]\tvalidation's rmse: 3.68192\n",
      "[1000]\tvalidation's rmse: 3.68208\n",
      "[1100]\tvalidation's rmse: 3.68199\n",
      "Early stopping, best iteration is:\n",
      "[906]\tvalidation's rmse: 3.68189\n",
      "Fold  5 RMSE : 3.681893\n",
      "Full RMSE score 3.763750\n",
      "********************************************************************************\n",
      "Run lgbm - Done in 94s\n",
      "\n",
      "Full Model Run - Done in 94s\n",
      "\n"
     ]
    }
   ],
   "source": [
    "if __name__ == \"__main__\":\n",
    "    \n",
    "    with pp.timer(\"Full Model Run\"):\n",
    "        \n",
    "        print(\"Regrerssors will be fitted with {} out of {} features\".format(len(features), train_X.shape[1]))\n",
    "        \n",
    "        for m, fp in get_tree_models():\n",
    "        \n",
    "            with pp.timer(\"Run \" + m.name):\n",
    "                \n",
    "                model = tr.OOFRegressor(reg = m, nfolds = 5, stratified = False)\n",
    "                \n",
    "                model.fit(train_X.loc[:, features], train_y, **fp)\n",
    "                pred = model.predict(test_X.loc[:, features])\n",
    "                \n",
    "                cv_score = model.rmse_score_\n",
    "                feat_importance = model.importances_\n",
    "                \n",
    "                if debug_size == 0:\n",
    "                    submission = pp.submit_file(ids, pred, prefix_file_name = m.name, cv_score = cv_score)\n",
    "                \n",
    "                del model, pred, cv_score\n",
    "                gc.collect()\n",
    "                \n",
    "                print(\"*\" * 80)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>FEATURE</th>\n",
       "      <th>IMPORTANCE</th>\n",
       "      <th>FOLD</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>elapsed_time</td>\n",
       "      <td>2938</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>year</td>\n",
       "      <td>323</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>month</td>\n",
       "      <td>1079</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>feature_1_1</td>\n",
       "      <td>37</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>feature_1_2</td>\n",
       "      <td>77</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>feature_1_3</td>\n",
       "      <td>32</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>feature_1_4</td>\n",
       "      <td>12</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>feature_1_5</td>\n",
       "      <td>68</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>feature_2_1</td>\n",
       "      <td>141</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>feature_2_2</td>\n",
       "      <td>25</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>feature_2_3</td>\n",
       "      <td>126</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>feature_3_0</td>\n",
       "      <td>65</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>feature_3_1</td>\n",
       "      <td>17</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13</th>\n",
       "      <td>HT_transactions_count</td>\n",
       "      <td>370</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14</th>\n",
       "      <td>HT_merchant_id_NUNIQUE</td>\n",
       "      <td>513</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15</th>\n",
       "      <td>HT_merchant_category_id_NUNIQUE</td>\n",
       "      <td>327</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>16</th>\n",
       "      <td>HT_state_id_NUNIQUE</td>\n",
       "      <td>157</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>17</th>\n",
       "      <td>HT_city_id_NUNIQUE</td>\n",
       "      <td>313</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>18</th>\n",
       "      <td>HT_subsector_id_NUNIQUE</td>\n",
       "      <td>352</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>19</th>\n",
       "      <td>HT_installments_PTP</td>\n",
       "      <td>275</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>20</th>\n",
       "      <td>HT_installments_SUM</td>\n",
       "      <td>812</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>21</th>\n",
       "      <td>HT_installments_MEAN</td>\n",
       "      <td>662</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>22</th>\n",
       "      <td>HT_installments_MAX</td>\n",
       "      <td>128</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>23</th>\n",
       "      <td>HT_installments_MIN</td>\n",
       "      <td>209</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>24</th>\n",
       "      <td>HT_installments_STD</td>\n",
       "      <td>778</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25</th>\n",
       "      <td>HT_purchase_amount_PTP</td>\n",
       "      <td>722</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>26</th>\n",
       "      <td>HT_purchase_amount_SUM</td>\n",
       "      <td>700</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>27</th>\n",
       "      <td>HT_purchase_amount_MEAN</td>\n",
       "      <td>894</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>28</th>\n",
       "      <td>HT_purchase_amount_MAX</td>\n",
       "      <td>566</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>29</th>\n",
       "      <td>HT_purchase_amount_MIN</td>\n",
       "      <td>860</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>45</th>\n",
       "      <td>HT_hours_since_previous_MEAN</td>\n",
       "      <td>481</td>\n",
       "      <td>5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>46</th>\n",
       "      <td>HT_hours_since_previous_MAX</td>\n",
       "      <td>267</td>\n",
       "      <td>5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>47</th>\n",
       "      <td>HT_hours_since_previous_MIN</td>\n",
       "      <td>532</td>\n",
       "      <td>5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>48</th>\n",
       "      <td>HT_hours_since_previous_STD</td>\n",
       "      <td>547</td>\n",
       "      <td>5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>49</th>\n",
       "      <td>HT_authorized_flag_N_COUNT</td>\n",
       "      <td>866</td>\n",
       "      <td>5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>50</th>\n",
       "      <td>HT_authorized_flag_N_COUNT_NORM</td>\n",
       "      <td>902</td>\n",
       "      <td>5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>51</th>\n",
       "      <td>HT_authorized_flag_Y_COUNT</td>\n",
       "      <td>497</td>\n",
       "      <td>5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>52</th>\n",
       "      <td>HT_authorized_flag_Y_COUNT_NORM</td>\n",
       "      <td>465</td>\n",
       "      <td>5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>53</th>\n",
       "      <td>HT_category_3_A_COUNT</td>\n",
       "      <td>76</td>\n",
       "      <td>5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>54</th>\n",
       "      <td>HT_category_3_A_COUNT_NORM</td>\n",
       "      <td>63</td>\n",
       "      <td>5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>55</th>\n",
       "      <td>HT_category_3_B_COUNT</td>\n",
       "      <td>407</td>\n",
       "      <td>5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>56</th>\n",
       "      <td>HT_category_3_B_COUNT_NORM</td>\n",
       "      <td>424</td>\n",
       "      <td>5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>57</th>\n",
       "      <td>HT_category_3_C_COUNT</td>\n",
       "      <td>305</td>\n",
       "      <td>5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>58</th>\n",
       "      <td>HT_category_3_C_COUNT_NORM</td>\n",
       "      <td>389</td>\n",
       "      <td>5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>59</th>\n",
       "      <td>HT_category_1_N_COUNT</td>\n",
       "      <td>275</td>\n",
       "      <td>5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>60</th>\n",
       "      <td>HT_category_1_N_COUNT_NORM</td>\n",
       "      <td>622</td>\n",
       "      <td>5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>61</th>\n",
       "      <td>HT_category_1_Y_COUNT</td>\n",
       "      <td>907</td>\n",
       "      <td>5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>62</th>\n",
       "      <td>HT_category_1_Y_COUNT_NORM</td>\n",
       "      <td>357</td>\n",
       "      <td>5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>63</th>\n",
       "      <td>HT_category_2_1.0_COUNT</td>\n",
       "      <td>442</td>\n",
       "      <td>5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>64</th>\n",
       "      <td>HT_category_2_1.0_COUNT_NORM</td>\n",
       "      <td>390</td>\n",
       "      <td>5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>65</th>\n",
       "      <td>HT_category_2_2.0_COUNT</td>\n",
       "      <td>45</td>\n",
       "      <td>5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>66</th>\n",
       "      <td>HT_category_2_2.0_COUNT_NORM</td>\n",
       "      <td>90</td>\n",
       "      <td>5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>67</th>\n",
       "      <td>HT_category_2_3.0_COUNT</td>\n",
       "      <td>89</td>\n",
       "      <td>5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>68</th>\n",
       "      <td>HT_category_2_3.0_COUNT_NORM</td>\n",
       "      <td>174</td>\n",
       "      <td>5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>69</th>\n",
       "      <td>HT_category_2_4.0_COUNT</td>\n",
       "      <td>136</td>\n",
       "      <td>5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>70</th>\n",
       "      <td>HT_category_2_4.0_COUNT_NORM</td>\n",
       "      <td>121</td>\n",
       "      <td>5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>71</th>\n",
       "      <td>HT_category_2_5.0_COUNT</td>\n",
       "      <td>99</td>\n",
       "      <td>5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>72</th>\n",
       "      <td>HT_category_2_5.0_COUNT_NORM</td>\n",
       "      <td>120</td>\n",
       "      <td>5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>73</th>\n",
       "      <td>HT_transactions_merchant</td>\n",
       "      <td>609</td>\n",
       "      <td>5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>74</th>\n",
       "      <td>HT_transactions_merchant_cat</td>\n",
       "      <td>574</td>\n",
       "      <td>5</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>375 rows × 3 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                            FEATURE  IMPORTANCE  FOLD\n",
       "0                      elapsed_time        2938     1\n",
       "1                              year         323     1\n",
       "2                             month        1079     1\n",
       "3                       feature_1_1          37     1\n",
       "4                       feature_1_2          77     1\n",
       "5                       feature_1_3          32     1\n",
       "6                       feature_1_4          12     1\n",
       "7                       feature_1_5          68     1\n",
       "8                       feature_2_1         141     1\n",
       "9                       feature_2_2          25     1\n",
       "10                      feature_2_3         126     1\n",
       "11                      feature_3_0          65     1\n",
       "12                      feature_3_1          17     1\n",
       "13            HT_transactions_count         370     1\n",
       "14           HT_merchant_id_NUNIQUE         513     1\n",
       "15  HT_merchant_category_id_NUNIQUE         327     1\n",
       "16              HT_state_id_NUNIQUE         157     1\n",
       "17               HT_city_id_NUNIQUE         313     1\n",
       "18          HT_subsector_id_NUNIQUE         352     1\n",
       "19              HT_installments_PTP         275     1\n",
       "20              HT_installments_SUM         812     1\n",
       "21             HT_installments_MEAN         662     1\n",
       "22              HT_installments_MAX         128     1\n",
       "23              HT_installments_MIN         209     1\n",
       "24              HT_installments_STD         778     1\n",
       "25           HT_purchase_amount_PTP         722     1\n",
       "26           HT_purchase_amount_SUM         700     1\n",
       "27          HT_purchase_amount_MEAN         894     1\n",
       "28           HT_purchase_amount_MAX         566     1\n",
       "29           HT_purchase_amount_MIN         860     1\n",
       "..                              ...         ...   ...\n",
       "45     HT_hours_since_previous_MEAN         481     5\n",
       "46      HT_hours_since_previous_MAX         267     5\n",
       "47      HT_hours_since_previous_MIN         532     5\n",
       "48      HT_hours_since_previous_STD         547     5\n",
       "49       HT_authorized_flag_N_COUNT         866     5\n",
       "50  HT_authorized_flag_N_COUNT_NORM         902     5\n",
       "51       HT_authorized_flag_Y_COUNT         497     5\n",
       "52  HT_authorized_flag_Y_COUNT_NORM         465     5\n",
       "53            HT_category_3_A_COUNT          76     5\n",
       "54       HT_category_3_A_COUNT_NORM          63     5\n",
       "55            HT_category_3_B_COUNT         407     5\n",
       "56       HT_category_3_B_COUNT_NORM         424     5\n",
       "57            HT_category_3_C_COUNT         305     5\n",
       "58       HT_category_3_C_COUNT_NORM         389     5\n",
       "59            HT_category_1_N_COUNT         275     5\n",
       "60       HT_category_1_N_COUNT_NORM         622     5\n",
       "61            HT_category_1_Y_COUNT         907     5\n",
       "62       HT_category_1_Y_COUNT_NORM         357     5\n",
       "63          HT_category_2_1.0_COUNT         442     5\n",
       "64     HT_category_2_1.0_COUNT_NORM         390     5\n",
       "65          HT_category_2_2.0_COUNT          45     5\n",
       "66     HT_category_2_2.0_COUNT_NORM          90     5\n",
       "67          HT_category_2_3.0_COUNT          89     5\n",
       "68     HT_category_2_3.0_COUNT_NORM         174     5\n",
       "69          HT_category_2_4.0_COUNT         136     5\n",
       "70     HT_category_2_4.0_COUNT_NORM         121     5\n",
       "71          HT_category_2_5.0_COUNT          99     5\n",
       "72     HT_category_2_5.0_COUNT_NORM         120     5\n",
       "73         HT_transactions_merchant         609     5\n",
       "74     HT_transactions_merchant_cat         574     5\n",
       "\n",
       "[375 rows x 3 columns]"
      ]
     },
     "execution_count": 41,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "feat_importance"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using TensorFlow backend.\n"
     ]
    },
    {
     "ename": "ImportError",
     "evalue": "Traceback (most recent call last):\n  File \"/home/fernando_carneiro/anaconda3/envs/tensorflow/lib/python3.6/site-packages/tensorflow/python/pywrap_tensorflow.py\", line 58, in <module>\n    from tensorflow.python.pywrap_tensorflow_internal import *\n  File \"/home/fernando_carneiro/anaconda3/envs/tensorflow/lib/python3.6/site-packages/tensorflow/python/pywrap_tensorflow_internal.py\", line 28, in <module>\n    _pywrap_tensorflow_internal = swig_import_helper()\n  File \"/home/fernando_carneiro/anaconda3/envs/tensorflow/lib/python3.6/site-packages/tensorflow/python/pywrap_tensorflow_internal.py\", line 24, in swig_import_helper\n    _mod = imp.load_module('_pywrap_tensorflow_internal', fp, pathname, description)\n  File \"/home/fernando_carneiro/anaconda3/envs/tensorflow/lib/python3.6/imp.py\", line 243, in load_module\n    return load_dynamic(name, filename, file)\n  File \"/home/fernando_carneiro/anaconda3/envs/tensorflow/lib/python3.6/imp.py\", line 343, in load_dynamic\n    return _load(spec)\nImportError: libcuda.so.1: cannot open shared object file: No such file or directory\n\n\nFailed to load the native TensorFlow runtime.\n\nSee https://www.tensorflow.org/install/errors\n\nfor some common reasons and solutions.  Include the entire stack trace\nabove this error message when asking for help.",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mImportError\u001b[0m                               Traceback (most recent call last)",
      "\u001b[0;32m~/anaconda3/envs/tensorflow/lib/python3.6/site-packages/tensorflow/python/pywrap_tensorflow.py\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m     57\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 58\u001b[0;31m   \u001b[0;32mfrom\u001b[0m \u001b[0mtensorflow\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpython\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpywrap_tensorflow_internal\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0;34m*\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     59\u001b[0m   \u001b[0;32mfrom\u001b[0m \u001b[0mtensorflow\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpython\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpywrap_tensorflow_internal\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0m__version__\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/envs/tensorflow/lib/python3.6/site-packages/tensorflow/python/pywrap_tensorflow_internal.py\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m     27\u001b[0m             \u001b[0;32mreturn\u001b[0m \u001b[0m_mod\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 28\u001b[0;31m     \u001b[0m_pywrap_tensorflow_internal\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mswig_import_helper\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     29\u001b[0m     \u001b[0;32mdel\u001b[0m \u001b[0mswig_import_helper\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/envs/tensorflow/lib/python3.6/site-packages/tensorflow/python/pywrap_tensorflow_internal.py\u001b[0m in \u001b[0;36mswig_import_helper\u001b[0;34m()\u001b[0m\n\u001b[1;32m     23\u001b[0m             \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 24\u001b[0;31m                 \u001b[0m_mod\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mimp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mload_module\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'_pywrap_tensorflow_internal'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfp\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mpathname\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdescription\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     25\u001b[0m             \u001b[0;32mfinally\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/envs/tensorflow/lib/python3.6/imp.py\u001b[0m in \u001b[0;36mload_module\u001b[0;34m(name, file, filename, details)\u001b[0m\n\u001b[1;32m    242\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 243\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mload_dynamic\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mname\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfilename\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfile\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    244\u001b[0m     \u001b[0;32melif\u001b[0m \u001b[0mtype_\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0mPKG_DIRECTORY\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/envs/tensorflow/lib/python3.6/imp.py\u001b[0m in \u001b[0;36mload_dynamic\u001b[0;34m(name, path, file)\u001b[0m\n\u001b[1;32m    342\u001b[0m             name=name, loader=loader, origin=path)\n\u001b[0;32m--> 343\u001b[0;31m         \u001b[0;32mreturn\u001b[0m \u001b[0m_load\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mspec\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    344\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mImportError\u001b[0m: libcuda.so.1: cannot open shared object file: No such file or directory",
      "\nDuring handling of the above exception, another exception occurred:\n",
      "\u001b[0;31mImportError\u001b[0m                               Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-1-130f4d694a57>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0;32mfrom\u001b[0m \u001b[0mkeras\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mlayers\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mDropout\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mFlatten\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mDense\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      2\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0mkeras\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmodels\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mSequential\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      3\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      4\u001b[0m \u001b[0;32mdef\u001b[0m \u001b[0mbaseline_nn\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mn_features\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      5\u001b[0m     \u001b[0mmodel\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mSequential\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/envs/tensorflow/lib/python3.6/site-packages/keras/__init__.py\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0m__future__\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mabsolute_import\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      2\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 3\u001b[0;31m \u001b[0;32mfrom\u001b[0m \u001b[0;34m.\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mutils\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      4\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0;34m.\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mactivations\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      5\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0;34m.\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mapplications\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/envs/tensorflow/lib/python3.6/site-packages/keras/utils/__init__.py\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      4\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0;34m.\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mdata_utils\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      5\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0;34m.\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mio_utils\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 6\u001b[0;31m \u001b[0;32mfrom\u001b[0m \u001b[0;34m.\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mconv_utils\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      7\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      8\u001b[0m \u001b[0;31m# Globally-importable utils.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/envs/tensorflow/lib/python3.6/site-packages/keras/utils/conv_utils.py\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      7\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0msix\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmoves\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mrange\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      8\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mnumpy\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0mnp\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 9\u001b[0;31m \u001b[0;32mfrom\u001b[0m \u001b[0;34m.\u001b[0m\u001b[0;34m.\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mbackend\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0mK\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     10\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     11\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/envs/tensorflow/lib/python3.6/site-packages/keras/backend/__init__.py\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m     87\u001b[0m \u001b[0;32melif\u001b[0m \u001b[0m_BACKEND\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0;34m'tensorflow'\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     88\u001b[0m     \u001b[0msys\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mstderr\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mwrite\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'Using TensorFlow backend.\\n'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 89\u001b[0;31m     \u001b[0;32mfrom\u001b[0m \u001b[0;34m.\u001b[0m\u001b[0mtensorflow_backend\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0;34m*\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     90\u001b[0m \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     91\u001b[0m     \u001b[0;31m# Try and load external backend.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/envs/tensorflow/lib/python3.6/site-packages/keras/backend/tensorflow_backend.py\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      3\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0m__future__\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mprint_function\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      4\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 5\u001b[0;31m \u001b[0;32mimport\u001b[0m \u001b[0mtensorflow\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0mtf\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      6\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0mtensorflow\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpython\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mframework\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mops\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0mtf_ops\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      7\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0mtensorflow\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpython\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtraining\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mmoving_averages\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/envs/tensorflow/lib/python3.6/site-packages/tensorflow/__init__.py\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m     22\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     23\u001b[0m \u001b[0;31m# pylint: disable=g-bad-import-order\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 24\u001b[0;31m \u001b[0;32mfrom\u001b[0m \u001b[0mtensorflow\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpython\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mpywrap_tensorflow\u001b[0m  \u001b[0;31m# pylint: disable=unused-import\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     25\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     26\u001b[0m \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/envs/tensorflow/lib/python3.6/site-packages/tensorflow/python/__init__.py\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m     47\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mnumpy\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0mnp\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     48\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 49\u001b[0;31m \u001b[0;32mfrom\u001b[0m \u001b[0mtensorflow\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpython\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mpywrap_tensorflow\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     50\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     51\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0mtensorflow\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpython\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtools\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mcomponent_api_helper\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/envs/tensorflow/lib/python3.6/site-packages/tensorflow/python/pywrap_tensorflow.py\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m     72\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0msome\u001b[0m \u001b[0mcommon\u001b[0m \u001b[0mreasons\u001b[0m \u001b[0;32mand\u001b[0m \u001b[0msolutions\u001b[0m\u001b[0;34m.\u001b[0m  \u001b[0mInclude\u001b[0m \u001b[0mthe\u001b[0m \u001b[0mentire\u001b[0m \u001b[0mstack\u001b[0m \u001b[0mtrace\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     73\u001b[0m above this error message when asking for help.\"\"\" % traceback.format_exc()\n\u001b[0;32m---> 74\u001b[0;31m   \u001b[0;32mraise\u001b[0m \u001b[0mImportError\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmsg\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     75\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     76\u001b[0m \u001b[0;31m# pylint: enable=wildcard-import,g-import-not-at-top,unused-import,line-too-long\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mImportError\u001b[0m: Traceback (most recent call last):\n  File \"/home/fernando_carneiro/anaconda3/envs/tensorflow/lib/python3.6/site-packages/tensorflow/python/pywrap_tensorflow.py\", line 58, in <module>\n    from tensorflow.python.pywrap_tensorflow_internal import *\n  File \"/home/fernando_carneiro/anaconda3/envs/tensorflow/lib/python3.6/site-packages/tensorflow/python/pywrap_tensorflow_internal.py\", line 28, in <module>\n    _pywrap_tensorflow_internal = swig_import_helper()\n  File \"/home/fernando_carneiro/anaconda3/envs/tensorflow/lib/python3.6/site-packages/tensorflow/python/pywrap_tensorflow_internal.py\", line 24, in swig_import_helper\n    _mod = imp.load_module('_pywrap_tensorflow_internal', fp, pathname, description)\n  File \"/home/fernando_carneiro/anaconda3/envs/tensorflow/lib/python3.6/imp.py\", line 243, in load_module\n    return load_dynamic(name, filename, file)\n  File \"/home/fernando_carneiro/anaconda3/envs/tensorflow/lib/python3.6/imp.py\", line 343, in load_dynamic\n    return _load(spec)\nImportError: libcuda.so.1: cannot open shared object file: No such file or directory\n\n\nFailed to load the native TensorFlow runtime.\n\nSee https://www.tensorflow.org/install/errors\n\nfor some common reasons and solutions.  Include the entire stack trace\nabove this error message when asking for help."
     ]
    }
   ],
   "source": [
    "from keras.layers import Dropout, Flatten, Dense\n",
    "from keras.models import Sequential\n",
    "\n",
    "def baseline_nn(n_features):\n",
    "    model = Sequential()\n",
    "    model.add(Dense(50, input_dim=n_features, init='normal', activation='relu'))\n",
    "    model.add(Dense(1, init='normal'))\n",
    "    model.compile(loss='mean_squared_error', optimizer='adam')\n",
    "    return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/anaconda3/envs/kaggle/lib/python3.6/importlib/_bootstrap.py:205: ImportWarning: can't resolve package from __spec__ or __package__, falling back on __name__ and __path__\n",
      "  return f(*args, **kwds)\n"
     ]
    }
   ],
   "source": [
    "from sklearn.model_selection import cross_val_score\n",
    "from sklearn.linear_model import ElasticNet, Lasso, BayesianRidge, Ridge, SGDRegressor, LassoLars\n",
    "from sklearn.ensemble import RandomForestRegressor, GradientBoostingRegressor, ExtraTreesRegressor\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "model_lasso = Lasso(alpha = 0.000507)\n",
    "model_ridge = Ridge()\n",
    "model_ENet = ElasticNet(alpha=0.0005, l1_ratio=.9, random_state=3, max_iter = 10000)\n",
    "model_rforest = RandomForestRegressor()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[ 3.82214121  3.86294031  3.86954698]\n"
     ]
    }
   ],
   "source": [
    "print(np.sqrt((-cross_val_score(model_rforest, train_X, train_y, cv=3, scoring=\"neg_mean_squared_error\"))))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python [conda env:tensorflow]",
   "language": "python",
   "name": "conda-env-tensorflow-py"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
